import logging
from datetime import datetime
from typing import Dict, List, Any, Optional

from langchain_core.messages import AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langgraph.prebuilt import ToolNode


class AgentExecutorService:
    """MCP ë„êµ¬ ì‹¤í–‰ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤"""

    def __init__(self, model, tools):
        self.model = model
        self.tools = tools
        self.logger = logging.getLogger(__name__)

    async def execute_tools(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹¤ì œ MCP ë„êµ¬ ì‹¤í–‰"""
        self.logger.info("MCP ë„êµ¬ ì‹¤í–‰ ë‹¨ê³„...")

        # ê³„íšì´ ìƒëµë˜ì—ˆê±°ë‚˜ ì¶”ê°€ ë„êµ¬ê°€ ë¶ˆí•„ìš”í•œ ê²½ìš° ê±´ë„ˆë›°ê¸°
        if state["current_step"] in ["plan_skipped", "plan_failed"]:
            self.logger.info("ê³„íš ë‹¨ê³„ì—ì„œ ë„êµ¬ ì‹¤í–‰ì´ ë¶ˆí•„ìš”í•˜ë‹¤ê³  íŒë‹¨ë¨ - ë„êµ¬ ì‹¤í–‰ ìƒëµ")
            state["current_step"] = "tools_skipped"
            return state

        # ì´ë¯¸ ì¶©ë¶„í•œ ê²°ê³¼ê°€ ìˆëŠ”ì§€ ì¬í™•ì¸
        if state["evaluation_results"]:
            latest_evaluation = state["evaluation_results"][-1]
            confidence = latest_evaluation.get("confidence", 0.0)
            if confidence >= 1.0:
                self.logger.info(f"ì™„ë²½í•œ ì‹ ë¢°ë„({confidence:.2f}) ë‹¬ì„± - ë„êµ¬ ì‹¤í–‰ ìƒëµ")
                state["current_step"] = "tools_skipped"
                return state

        try:
            if not self.tools:
                self.logger.info("ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ê°€ ì—†ìŒ. ëª¨ë¸ ì§€ì‹ë§Œìœ¼ë¡œ ë‹µë³€ ìƒì„±")
                state["current_step"] = "tools_executed"
                return state

            # ì´ë¯¸ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ëœ ë„êµ¬ë“¤ í™•ì¸
            executed_tools = set()
            for tool_result in state["tool_results"]:
                if tool_result.get("success", False):
                    executed_tools.add(tool_result.get("tool_name", ""))

            # ì•„ì§ ì‹¤í–‰ë˜ì§€ ì•Šì€ ë„êµ¬ê°€ ìˆëŠ”ì§€ í™•ì¸
            available_tools = [tool for tool in self.tools
                               if getattr(tool, 'name', str(tool)) not in executed_tools]

            if not available_tools:
                self.logger.info("ëª¨ë“  ê´€ë ¨ ë„êµ¬ê°€ ì´ë¯¸ ì‹¤í–‰ë¨ - ì¶”ê°€ ì‹¤í–‰ ìƒëµ")
                state["current_step"] = "tools_skipped"
                return state

            # ğŸš€ ê°œì„ ëœ ë„êµ¬ ì„ íƒ ë¡œì§
            selected_tool = await self.select_best_tool(state["user_query"], available_tools)

            if not selected_tool:
                self.logger.info("ì‚¬ìš©ì ìš”ì²­ì— ì í•©í•œ ë„êµ¬ê°€ ì—†ìŒ")
                state["current_step"] = "tools_skipped"
                return state

            tool_name = getattr(selected_tool, 'name', 'mcp_tool')

            self.logger.info(f"ìƒˆë¡œìš´ ë„êµ¬ '{tool_name}' ì‹¤í–‰ ì¤‘...")

            # ì‹¤í–‰ ê³„íšì—ì„œ ì¶”ì¶œí•œ ë„êµ¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ ë„êµ¬ ì‹¤í–‰
            tool_node = ToolNode([selected_tool])

            # ë„êµ¬ ì‹¤í–‰ì„ ìœ„í•œ ë©”ì‹œì§€ êµ¬ì„±
            tool_message = AIMessage(
                content="",
                tool_calls=[{
                    "name": tool_name,
                    "args": {"query": state["user_query"]},
                    "id": f"call_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                }]
            )

            # ì‹¤ì œ ë„êµ¬ ì‹¤í–‰
            tool_response = await tool_node.ainvoke({"messages": [tool_message]})

            if tool_response and "messages" in tool_response:
                for msg in tool_response["messages"]:
                    if hasattr(msg, 'content'):
                        tool_result = {
                            "tool_name": tool_name,
                            "input": state["user_query"],
                            "output": msg.content,
                            "timestamp": datetime.now().isoformat(),
                            "success": True
                        }

                        state["tool_results"].append(tool_result)
                        state["reasoning_trace"].append(f"ìƒˆë¡œìš´ MCP ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ: {tool_result['tool_name']}")
                        self.logger.info(f"ë„êµ¬ '{tool_result['tool_name']}' ì‹¤í–‰ ì„±ê³µ")
            else:
                self.logger.warning("ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")

            state["current_step"] = "tools_executed"

        except Exception as e:
            self.logger.error(f"MCP ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            # ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œì—ë„ ëª¨ë¸ ì§€ì‹ìœ¼ë¡œ ë‹µë³€ ì‹œë„
            tool_result = {
                "tool_name": "fallback_knowledge",
                "input": state["user_query"],
                "output": f"ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨ë¡œ ëª¨ë¸ ì§€ì‹ ê¸°ë°˜ ë‹µë³€ ì‹œë„: {str(e)}",
                "timestamp": datetime.now().isoformat(),
                "success": False
            }
            state["tool_results"].append(tool_result)
            state["current_step"] = "tools_executed"

        return state

    async def select_best_tool(self, user_query: str, available_tools: List) -> Optional[Any]:
        """ì‚¬ìš©ì ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ ì„ íƒ"""
        if not available_tools:
            return None

        if len(available_tools) == 1:
            return available_tools[0]

        # ë„êµ¬ëª…ê³¼ ì„¤ëª… ìˆ˜ì§‘
        tool_descriptions = []
        for tool in available_tools:
            tool_name = getattr(tool, 'name', str(tool))
            tool_descriptions.append(f"- {tool_name}")

        # LLM ê¸°ë°˜ ë„êµ¬ ì„ íƒ
        selection_prompt = ChatPromptTemplate.from_messages([
            ("system", """ì‚¬ìš©ì ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:
{tools}

**ì„ íƒ ê¸°ì¤€:**
- íŒŒì¼ ì‚­ì œ ìš”ì²­ â†’ delete_file ì„ íƒ
- ì‹œê°„ ì¡°íšŒ ìš”ì²­ â†’ get_current_time ì„ íƒ
- ê´€ë ¨ ì—†ëŠ” ë„êµ¬ëŠ” ì ˆëŒ€ ì„ íƒí•˜ì§€ ë§ˆì„¸ìš”

ì •í™•í•œ ë„êµ¬ëª…ë§Œ ë°˜í™˜í•˜ì„¸ìš”."""),
            ("human", "ì‚¬ìš©ì ìš”ì²­: {query}")
        ])

        try:
            response = await self.model.ainvoke(
                selection_prompt.format_messages(
                    query=user_query,
                    tools="\n".join(tool_descriptions)
                )
            )

            selected_tool_name = response.content.strip()
            self.logger.info(f"LLMì´ ì„ íƒí•œ ë„êµ¬: '{selected_tool_name}'")

            # ì„ íƒëœ ë„êµ¬ ì°¾ê¸°
            for tool in available_tools:
                if getattr(tool, 'name', str(tool)) == selected_tool_name:
                    self.logger.info(f"âœ… ì ì ˆí•œ ë„êµ¬ ì„ íƒë¨: {selected_tool_name}")
                    return tool

            # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ë„êµ¬ (í´ë°±)
            self.logger.warning(f"ë„êµ¬ ë§¤ì¹­ ì‹¤íŒ¨. ì²« ë²ˆì§¸ ë„êµ¬ ì‚¬ìš©: {getattr(available_tools[0], 'name', 'unknown')}")
            return available_tools[0]

        except Exception as e:
            self.logger.error(f"ë„êµ¬ ì„ íƒ ì‹¤íŒ¨: {e}")
            return available_tools[0]
