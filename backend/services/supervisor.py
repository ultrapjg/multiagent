import asyncio
import json
import logging
from enum import Enum
from typing import Dict, List, Any, AsyncGenerator, Optional, Literal, TypedDict, Callable

from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_ollama import ChatOllama
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.graph import StateGraph, END, START

from .agent_executor import AgentExecutorService
from .result_aggregator import ResultAggregatorService


class WorkflowState(TypedDict):
    messages: List[Any]
    user_query: str
    current_step: str
    tool_results: List[Dict[str, Any]]
    evaluation_results: List[Dict[str, Any]]
    confidence_score: float
    next_action: str
    iteration_count: int
    max_iterations: int
    final_answer: str
    reasoning_trace: List[str]
    # Human-in-the-loop ê´€ë ¨ í•„ë“œ
    human_approval_needed: bool
    human_input_requested: bool
    human_response: Optional[str]
    pending_decision: Optional[Dict[str, Any]]
    hitl_enabled: bool
    # ì¶”ê°€ HITL ìƒíƒœ ê´€ë¦¬
    approval_type: Optional[str]
    approval_message: Optional[str]


class ToolEvaluationResult(Enum):
    """ë„êµ¬ í‰ê°€ ê²°ê³¼"""
    SUCCESS = "success"
    PARTIAL = "partial"
    FAILURE = "failure"
    NEEDS_MORE_INFO = "needs_more_info"


class HumanApprovalType(Enum):
    """Human approval íƒ€ì…"""
    TOOL_EXECUTION = "tool_execution"
    HIGH_IMPACT_DECISION = "high_impact_decision"
    LOW_CONFIDENCE = "low_confidence"
    FINAL_ANSWER = "final_answer"


class SupervisorService:
    """Human-in-the-loop ê¸°ëŠ¥ì„ í¬í•¨í•œ ë™ì  ì›Œí¬í”Œë¡œìš° ê¸°ë°˜ LangGraph MCP ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤"""

    def __init__(self):
        self.mcp_client = None
        self.model = None
        self.evaluator_model = None
        self.tools = []
        self.workflow = None
        self.checkpointer = InMemorySaver()
        self.timeout_seconds = 120

        # Human-in-the-loop ì„¤ì •
        self.hitl_config = {
            "enabled": True,
            "require_approval_for_tools": False,  # ë„êµ¬ ì‹¤í–‰ ì „ ìŠ¹ì¸ í•„ìš”
            "require_approval_for_low_confidence": False,  # ë‚®ì€ ì‹ ë¢°ë„ ì‹œ ìŠ¹ì¸ í•„ìš”
            "require_approval_for_final_answer": False,  # ìµœì¢… ë‹µë³€ ì „ ìŠ¹ì¸ í•„ìš”
            "confidence_threshold": 0.7,  # ì´ ê°’ ì´í•˜ë©´ human approval ìš”ì²­
            "high_impact_tools": ["file_operations", "external_api_calls", "system_commands"]  # ê³ ìœ„í—˜ ë„êµ¬
        }

        # Human input callback - ê¸°ë³¸ callback ì„¤ì •
        self.human_input_callback: Optional[Callable] = self._default_human_input_callback

        # Human input queue for async communication
        self.human_input_queue = asyncio.Queue()
        self.waiting_for_human_input = False
        self.pending_approval_message = None
        self.pending_approval_context = None

        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)

        self.agent_executor = None
        self.result_aggregator = None

    def _default_human_input_callback(self, message: str, context: Dict) -> str:
        """ê¸°ë³¸ human input callback - ë¹„ë™ê¸° ëŒ€ê¸°ë¥¼ ìœ„í•œ í”Œë˜ê·¸ ì„¤ì •"""
        self.logger.info("ê¸°ë³¸ human input callback í˜¸ì¶œë¨ - ë¹„ë™ê¸° ì…ë ¥ ëŒ€ê¸° ëª¨ë“œ")

        # ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì§ˆ ë©”ì‹œì§€ë¥¼ ì €ì¥
        self.pending_approval_message = message
        self.pending_approval_context = context

        # ë¹„ë™ê¸° ì…ë ¥ ëŒ€ê¸°ë¥¼ ìœ„í•œ íŠ¹ë³„í•œ í”Œë˜ê·¸ ë°˜í™˜
        return "__WAIT_FOR_ASYNC_INPUT__"

    def set_human_input_callback(self, callback: Callable[[str, Dict], str]):
        """Human input callback ì„¤ì •"""
        if callback is None:
            self.logger.warning("None callback ì „ë‹¬ë¨ - ê¸°ë³¸ callback ìœ ì§€")
            return

        self.human_input_callback = callback
        self.logger.info(f"Human input callback ì„¤ì • ì™„ë£Œ: {callback}")

    async def set_human_input_async(self, human_input: str) -> bool:
        """ë¹„ë™ê¸° human input ì„¤ì •"""
        try:
            self.logger.info(f"Human input ì„¤ì •: {human_input}")

            if hasattr(self, 'human_input_queue'):
                await self.human_input_queue.put(human_input)
                self.waiting_for_human_input = False
                self.logger.info("Human input íì— ì¶”ê°€ ì™„ë£Œ")
                return True
            else:
                self.logger.warning("human_input_queueê°€ ì—†ìŒ")
                return False

        except Exception as e:
            self.logger.error(f"Human input ì„¤ì • ì‹¤íŒ¨: {e}")
            return False

    def get_pending_approval_info(self) -> Dict[str, Any]:
        """í˜„ì¬ ëŒ€ê¸° ì¤‘ì¸ ìŠ¹ì¸ ì •ë³´ ë°˜í™˜"""
        if self.waiting_for_human_input:
            return {
                "waiting": True,
                "message": self.pending_approval_message,
                "context": self.pending_approval_context
            }
        return {"waiting": False}

    def configure_hitl(self, **config):
        """Human-in-the-loop ì„¤ì • ì—…ë°ì´íŠ¸"""
        self.hitl_config.update(config)
        self.logger.info(f"HITL ì„¤ì • ì—…ë°ì´íŠ¸: {self.hitl_config}")

    async def initialize_agent(self,
                               model_name: str = "qwen2.5:32b",
                               evaluator_model_name: Optional[str] = None,
                               mcp_config: Optional[Dict] = None,
                               system_prompt: Optional[str] = None,
                               hitl_enabled: bool = True,
                               human_input_callback: Optional[Callable] = None):
        """ë™ì  ì›Œí¬í”Œë¡œìš° ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        try:
            self.logger.info(f"HITL ì§€ì› ë™ì  ì›Œí¬í”Œë¡œìš° ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹œì‘: {model_name}")

            # Human input callback ì„¤ì •
            if human_input_callback:
                self.set_human_input_callback(human_input_callback)
                self.logger.info("ì´ˆê¸°í™” ì‹œ human input callback ì„¤ì •ë¨")

            # HITL ì„¤ì •
            self.hitl_config["enabled"] = hitl_enabled
            if hitl_enabled:
                self.hitl_config.update({
                    "require_approval_for_tools": True,  # ë„êµ¬ ìŠ¹ì¸ í™œì„±í™”
                    "require_approval_for_low_confidence": False,  # ë‚®ì€ ì‹ ë¢°ë„ ìŠ¹ì¸ í™œì„±í™”
                    "confidence_threshold": 0.8,  # ì„ê³„ê°’ì„ ë†’ì—¬ì„œ ë” ìì£¼ íŠ¸ë¦¬ê±°
                    # ê³ ìœ„í—˜ í‚¤ì›Œë“œ
                    "high_impact_tools": [
                        "ì‚­ì œ", "ì œê±°", "ì§€ìš°", "delete", "remove", "rm",
                        "íŒŒê´´", "destroy", "kill", "terminate",
                        "í¬ë§·", "format", "ì´ˆê¸°í™”", "reset",
                        "ìˆ˜ì •", "ë³€ê²½", "modify", "edit", "change",
                        "ì‹œìŠ¤í…œ", "system", "ê´€ë¦¬ì", "admin", "root"
                    ]
                })

            # ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
            await self.cleanup_mcp_client()

            # MCP ì„¤ì • ë¡œë“œ ë° ë„êµ¬ ì´ˆê¸°í™”
            if mcp_config is None:
                mcp_config = self.load_mcp_config()

            if mcp_config and mcp_config.get("mcpServers"):
                self.mcp_client = MultiServerMCPClient(mcp_config["mcpServers"])
                self.tools = await self.mcp_client.get_tools()
            else:
                self.tools = []

            # ë©”ì¸ ëª¨ë¸ê³¼ í‰ê°€ ëª¨ë¸ ì´ˆê¸°í™”
            self.model = self.create_model(model_name)
            self.evaluator_model = self.create_model(evaluator_model_name or model_name)

            # ë¶„ë¦¬ëœ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
            self.agent_executor = AgentExecutorService(self.model, self.tools)
            self.result_aggregator = ResultAggregatorService(self.model, self.evaluator_model, self.tools)

            # ë™ì  ì›Œí¬í”Œë¡œìš° ìƒì„±
            self.workflow = self._create_dynamic_workflow()

            self.logger.info(f"HITL ì§€ì› ë™ì  ì›Œí¬í”Œë¡œìš° ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ. ë„êµ¬ {len(self.tools)}ê°œ ë¡œë“œë¨")
            self.logger.info(f"HITL ê³ ìœ„í—˜ í‚¤ì›Œë“œ: {self.hitl_config.get('high_impact_tools', [])}")
            self.logger.info(f"Human input callback ìƒíƒœ: {'ì„¤ì •ë¨' if self.human_input_callback else 'ë¯¸ì„¤ì •'}")
            return True

        except Exception as e:
            self.logger.error(f"ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def _create_dynamic_workflow(self) -> StateGraph:
        """Human-in-the-loop ê¸°ëŠ¥ì„ í¬í•¨í•œ ë™ì  ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        workflow = StateGraph(WorkflowState)

        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("analyze_query", self._analyze_query)
        workflow.add_node("plan_execution", self._plan_execution)
        workflow.add_node("human_approval", self._human_approval)  # Human approval ë…¸ë“œ
        workflow.add_node("execute_tools", self._execute_tools_wrapper)
        workflow.add_node("evaluate_results", self._evaluate_results_wrapper)
        workflow.add_node("synthesize_answer", self._synthesize_answer_wrapper)
        workflow.add_node("quality_check", self._quality_check)
        workflow.add_node("simple_answer", self._simple_answer)
        workflow.add_node("human_input", self._human_input)  # Human input ë…¸ë“œ

        # ì›Œí¬í”Œë¡œìš° ì—°ê²°
        workflow.add_edge(START, "analyze_query")

        # ë¶„ì„ ë‹¨ê³„ í›„ ì¡°ê±´ë¶€ ë¶„ê¸°
        workflow.add_conditional_edges(
            "analyze_query",
            self._decide_after_analysis,
            {
                "simple": "simple_answer",
                "complex": "plan_execution"
            }
        )

        workflow.add_edge("simple_answer", END)

        # ê³„íš í›„ Human approval ì²´í¬
        workflow.add_conditional_edges(
            "plan_execution",
            self._decide_after_planning,
            {
                "execute": "execute_tools",
                "need_approval": "human_approval",  # Human approval í•„ìš”
                "skip_to_synthesize": "synthesize_answer",
                "end": END
            }
        )

        # Human approval í›„ ë¶„ê¸°
        workflow.add_conditional_edges(
            "human_approval",
            self._decide_after_approval,
            {
                "approved": "execute_tools",
                "rejected": "plan_execution",  # ë‹¤ì‹œ ê³„íš
                "modified": "plan_execution",  # ìˆ˜ì •ëœ ê³„íšìœ¼ë¡œ
                "need_input": "human_input"  # ì¶”ê°€ ì…ë ¥ í•„ìš”
            }
        )

        # Human input í›„ ê³„íšìœ¼ë¡œ ëŒì•„ê°€ê¸°
        workflow.add_edge("human_input", "plan_execution")

        workflow.add_edge("execute_tools", "evaluate_results")

        # í‰ê°€ í›„ ë‚®ì€ ì‹ ë¢°ë„ ì‹œ Human approval
        workflow.add_conditional_edges(
            "evaluate_results",
            self._decide_next_step,
            {
                "continue": "plan_execution",
                "synthesize": "synthesize_answer",
                "need_approval": "human_approval",  # ë‚®ì€ ì‹ ë¢°ë„ë¡œ ì¸í•œ approval
                "end": END
            }
        )

        workflow.add_edge("synthesize_answer", "quality_check")
        workflow.add_conditional_edges(
            "quality_check",
            self._decide_final_step,
            {
                "approved": END,
                "retry": "plan_execution",
                "need_approval": "human_approval"  # ìµœì¢… ë‹µë³€ ìŠ¹ì¸
            }
        )

        return workflow.compile(checkpointer=self.checkpointer)

    async def _analyze_query(self, state: WorkflowState) -> WorkflowState:
        """ì‚¬ìš©ì ì¿¼ë¦¬ ë¶„ì„"""
        self.logger.info("ì‚¬ìš©ì ì¿¼ë¦¬ ë¶„ì„ ì¤‘...")

        analysis_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê´€ì ì—ì„œ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì„¸ìš”:
1. ì¿¼ë¦¬ì˜ ì˜ë„ì™€ ëª©ì 
2. í•„ìš”í•œ ì •ë³´ì˜ ì¢…ë¥˜
3. ì í•©í•œ ë„êµ¬ë“¤
4. ì˜ˆìƒë˜ëŠ” ë³µì¡ë„ (1-10)
5. ë‹¨ê³„ë³„ í•´ê²° ê³„íš

**ì¤‘ìš”**: ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš° "ë„êµ¬ ë¶ˆí•„ìš”"ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:
- ë‹¨ìˆœí•œ ì¸ì‚¬ (ì•ˆë…•, ì•ˆë…•í•˜ì„¸ìš”, ë°˜ê°€ì›Œìš” ë“±)
- ì¼ë°˜ì ì¸ ì§ˆë¬¸ì´ë‚˜ ìƒì‹ ë¬¸ì˜
- ì°½ì˜ì  ê¸€ì“°ê¸° ìš”ì²­
- ì„¤ëª…ì´ë‚˜ ì •ì˜ ìš”ì²­
- ë„êµ¬ ì—†ì´ ëª¨ë¸ ì§€ì‹ìœ¼ë¡œ ì¶©ë¶„íˆ ë‹µë³€ ê°€ëŠ¥í•œ ê²½ìš°

Available tools: {tools}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "analysis": {{
    "intention_and_purpose": "ì¿¼ë¦¬ì˜ ì˜ë„ì™€ ëª©ì ",
    "type_of_information_required": "í•„ìš”í•œ ì •ë³´ ì¢…ë¥˜",
    "suitable_tools": "ì í•©í•œ ë„êµ¬ë“¤ ë˜ëŠ” 'ë„êµ¬ ë¶ˆí•„ìš”'",
    "expected_complexity": 1-10,
    "step_by_step_solution_plan": ["í•´ê²° ê³„íš"],
    "requires_tools": true/false
  }}
}}"""),
            ("human", "ì¿¼ë¦¬: {query}")
        ])

        tool_names = [tool.name if hasattr(tool, 'name') else str(tool) for tool in self.tools]

        try:
            response = await self.model.ainvoke(
                analysis_prompt.format_messages(
                    query=state["user_query"],
                    tools=", ".join(tool_names) if tool_names else "ì—†ìŒ"
                )
            )

            # JSON íŒŒì‹± ì‹œë„
            try:
                analysis_result = json.loads(response.content)
                requires_tools = analysis_result.get("analysis", {}).get("requires_tools", True)
                suitable_tools = analysis_result.get("analysis", {}).get("suitable_tools", "")

                # ë„êµ¬ê°€ í•„ìš” ì—†ëŠ” ê²½ìš° ì²´í¬
                if (not requires_tools or
                        "ë„êµ¬ ë¶ˆí•„ìš”" in suitable_tools or
                        "íŠ¹ì • ë„êµ¬ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤" in suitable_tools or
                        "ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸ ì‘ë‹µìœ¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤" in suitable_tools):
                    self.logger.info("ë„êµ¬ê°€ í•„ìš” ì—†ëŠ” ì¿¼ë¦¬ë¡œ íŒë‹¨ - ì§ì ‘ ë‹µë³€ ìƒì„±")
                    state["current_step"] = "simple_query"
                    state["reasoning_trace"].append("ë„êµ¬ê°€ í•„ìš” ì—†ëŠ” ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ íŒë‹¨ë˜ì–´ ì§ì ‘ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                    return state

            except json.JSONDecodeError:
                self.logger.warning("ë¶„ì„ ê²°ê³¼ JSON íŒŒì‹± ì‹¤íŒ¨ - ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ì§„í–‰")

            # ë¶„ì„ ê²°ê³¼ë¥¼ ìƒíƒœì— ì €ì¥
            state["reasoning_trace"].append(f"ì¿¼ë¦¬ ë¶„ì„: {response.content}")
            state["current_step"] = "query_analyzed"

        except Exception as e:
            self.logger.error(f"ì¿¼ë¦¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            state["reasoning_trace"].append(f"ì¿¼ë¦¬ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            state["current_step"] = "query_analyzed"  # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

        return state

    async def _plan_execution(self, state: WorkflowState) -> WorkflowState:
        """ì‹¤í–‰ ê³„íš ìˆ˜ë¦½"""
        self.logger.info("ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ì¤‘...")

        # ê³ ìœ„í—˜ í‚¤ì›Œë“œ ì²´í¬ ë° HITL ì„¤ì •ì„ ì—¬ê¸°ì„œ ë¨¼ì € ìˆ˜í–‰
        if self.hitl_config.get("enabled", False) and self.hitl_config.get("require_approval_for_tools", False):
            query_lower = state["user_query"].lower()
            high_impact_keywords = self.hitl_config.get("high_impact_tools", [])

            detected_keywords = []
            for keyword in high_impact_keywords:
                if keyword.lower() in query_lower:
                    detected_keywords.append(keyword)

            if detected_keywords:
                self.logger.info(f"ê³„íš ë‹¨ê³„ì—ì„œ ê³ ìœ„í—˜ í‚¤ì›Œë“œ ê°ì§€: {detected_keywords}")

                # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ í™•ì¸
                available_tools = []
                if self.tools:
                    for tool in self.tools:
                        tool_name = getattr(tool, 'name', str(tool))
                        available_tools.append(tool_name)

                relevant_tool_name = self._find_relevant_tool_by_keywords(detected_keywords)

                if relevant_tool_name:
                    tool_description = f"'{relevant_tool_name}' ë„êµ¬ë¥¼ í†µí•œ ê³ ìœ„í—˜ ì‘ì—…"
                    self.logger.info(f"í‚¤ì›Œë“œ '{detected_keywords}'ì— ì í•©í•œ ë„êµ¬ ì„ íƒ: {relevant_tool_name}")
                else:
                    # ì í•©í•œ ë„êµ¬ê°€ ì—†ìœ¼ë©´ ì¼ë°˜ ì‹œìŠ¤í…œ ì‘ì—…ìœ¼ë¡œ ë¶„ë¥˜
                    relevant_tool_name = "system_operation"
                    tool_description = f"'{', '.join(detected_keywords)}' í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì‹œìŠ¤í…œ ì‘ì—…"
                    self.logger.info("ì í•©í•œ ë„êµ¬ë¥¼ ì°¾ì§€ ëª»í•´ ì¼ë°˜ ì‹œìŠ¤í…œ ì‘ì—…ìœ¼ë¡œ ë¶„ë¥˜")

                # ìŠ¹ì¸ ë©”ì‹œì§€ ìƒì„±
                approval_message = f"""ğŸ”´ ê³ ìœ„í—˜ ì‘ì—… ìŠ¹ì¸ ìš”ì²­

ê°ì§€ëœ í‚¤ì›Œë“œ: {', '.join(detected_keywords)}
ì‹¤í–‰ ì˜ˆì • ë„êµ¬: {relevant_tool_name}
ì‘ì—… ë‚´ìš©: {tool_description}
ìš”ì²­ ë‚´ìš©: {state['user_query']}
ìœ„í—˜ë„: ë†’ìŒ

âš ï¸ ì´ ì‘ì—…ì€ ì‹œìŠ¤í…œì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì •ë§ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (approved/rejected/modified)"""

                # pending_decision ìƒì„±í•˜ì—¬ ìƒíƒœì— ì €ì¥
                state["pending_decision"] = {
                    "type": HumanApprovalType.TOOL_EXECUTION.value,
                    "tool_name": relevant_tool_name if available_tools else "ê³ ìœ„í—˜_ì‹œìŠ¤í…œ_ì‘ì—…",
                    "tool_args": {"query": state["user_query"]},
                    "reason": f"ê³ ìœ„í—˜ í‚¤ì›Œë“œ ê°ì§€: {', '.join(detected_keywords)}",
                    "keywords": detected_keywords,
                    "available_tools": available_tools,
                    "risk_level": "high"
                }
                state["approval_type"] = HumanApprovalType.TOOL_EXECUTION.value
                state["approval_message"] = approval_message
                state["human_approval_needed"] = True

                self.logger.info("HITL ì •ë³´ê°€ ìƒíƒœì— ì €ì¥ë¨")

        # ì²« ë²ˆì§¸ ë°˜ë³µì´ë©´ ë¬´ì¡°ê±´ ë„êµ¬ ì‹¤í–‰ ê³„íšì„ ì„¸ì›Œì•¼ í•¨
        if state["iteration_count"] == 0:
            self.logger.info("ì²« ë²ˆì§¸ ë°˜ë³µ - ë„êµ¬ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½")
        else:
            # ì´ì „ í‰ê°€ ê²°ê³¼ í™•ì¸ - ì´ë¯¸ ì¶©ë¶„í•œ ê²°ê³¼ê°€ ìˆëŠ”ì§€ ì²´í¬
            if state["evaluation_results"]:
                latest_evaluation = state["evaluation_results"][-1]
                confidence = latest_evaluation.get("confidence", 0.0)
                evaluation_type = latest_evaluation.get("evaluation", "")

                # ì´ë¯¸ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ë‹¬ì„±í–ˆë‹¤ë©´ ì¶”ê°€ ë„êµ¬ ì‹¤í–‰ ìƒëµ
                if confidence >= 0.95 or evaluation_type == ToolEvaluationResult.SUCCESS.value:
                    self.logger.info(f"ì´ë¯¸ ì¶©ë¶„í•œ ê²°ê³¼ ë‹¬ì„± (ì‹ ë¢°ë„: {confidence:.2f}) - ë„êµ¬ ì‹¤í–‰ ìƒëµ")
                    state["reasoning_trace"].append("ì´ë¯¸ ì¶©ë¶„í•œ ê²°ê³¼ë¥¼ ì–»ì—ˆìœ¼ë¯€ë¡œ ì¶”ê°€ ë„êµ¬ ì‹¤í–‰ì„ ìƒëµí•©ë‹ˆë‹¤.")
                    state["current_step"] = "plan_skipped"
                    return state

        # ì´ì „ ë„êµ¬ ê²°ê³¼ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
        executed_tools = set()
        for tool_result in state["tool_results"]:
            if tool_result.get("success", False):
                executed_tools.add(tool_result.get("tool_name", ""))

        planning_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ í™•ì¸í•˜ì—¬ ì‹¤í–‰ ê³„íšì„ ì„¸ìš°ì„¸ìš”.

**ì¤‘ìš” ê·œì¹™**:
1. ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì—ì„œë§Œ ë„êµ¬ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. ì‚¬ìš©ì ìš”ì²­ì— ì í•©í•œ ë„êµ¬ê°€ ì—†ë‹¤ë©´ "ì í•©í•œ ë„êµ¬ ì—†ìŒ"ì´ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.
3. ì´ë¯¸ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ëœ ë„êµ¬ëŠ” ë‹¤ì‹œ ì‹¤í–‰í•˜ì§€ ë§ˆì„¸ìš”.
4. ì²« ë²ˆì§¸ ì‹¤í–‰ì´ë¼ë©´ ì‚¬ìš©ì ì¿¼ë¦¬ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.

í˜„ì¬ ìƒí™©:
- ì‚¬ìš©ì ì¿¼ë¦¬: {query}
- í˜„ì¬ ë°˜ë³µ: {iteration}/{max_iterations}
- ì´ì „ ë„êµ¬ ê²°ê³¼: {tool_results}
- ì´ì „ í‰ê°€ ê²°ê³¼: {evaluation_results}
- ì´ë¯¸ ì‹¤í–‰ëœ ë„êµ¬: {executed_tools}

**ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬**: {tools}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ê³„íšì„ ì œì‹œí•˜ì„¸ìš”:
- ë‹¤ìŒì— ì‚¬ìš©í•  ë„êµ¬ë“¤: [ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë„êµ¬ë§Œ ë‚˜ì—´]
- ê° ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ : [êµ¬ì²´ì  ì´ìœ ]
- ì˜ˆìƒë˜ëŠ” ê²°ê³¼: [ì˜ˆìƒ ê²°ê³¼]
- ì í•©í•œ ë„êµ¬ê°€ ì—†ë‹¤ë©´: "ì í•©í•œ ë„êµ¬ ì—†ìŒ - ì‚¬ìš©ìì—ê²Œ ì§ì ‘ ì„¤ëª… í•„ìš”"
- ì¶”ê°€ ë„êµ¬ê°€ í•„ìš”í•˜ì§€ ì•Šë‹¤ë©´: "ì¶”ê°€ ë„êµ¬ ë¶ˆí•„ìš”"

**ì£¼ì˜**: ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë„êµ¬(ì˜ˆ: get_weather, search_web ë“±)ë¥¼ ì œì•ˆí•˜ì§€ ë§ˆì„¸ìš”."""),
            ("human", "ë‹¤ìŒ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.")
        ])

        tool_names = [tool.name if hasattr(tool, 'name') else str(tool) for tool in self.tools]

        try:
            response = await self.model.ainvoke(
                planning_prompt.format_messages(
                    query=state["user_query"],
                    iteration=state["iteration_count"],
                    max_iterations=state["max_iterations"],
                    tool_results=state["tool_results"][-3:] if state["tool_results"] else "ì—†ìŒ",
                    evaluation_results=state["evaluation_results"][-3:] if state["evaluation_results"] else "ì—†ìŒ",
                    executed_tools=", ".join(executed_tools) if executed_tools else "ì—†ìŒ",
                    tools=", ".join(tool_names) if tool_names else "ì—†ìŒ"
                )
            )

            response_content = response.content.lower()

            # ì í•©í•œ ë„êµ¬ê°€ ì—†ëŠ” ê²½ìš° ì²´í¬
            if any(phrase in response_content for phrase in ["ì í•©í•œ ë„êµ¬ ì—†ìŒ", "ì‚¬ìš©ìì—ê²Œ ì§ì ‘ ì„¤ëª…", "ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´"]):
                self.logger.info("ì‚¬ìš©ì ìš”ì²­ì— ì í•©í•œ ë„êµ¬ê°€ ì—†ìŒ - ë„êµ¬ ì‹¤í–‰ ì—†ì´ ì§ì ‘ ë‹µë³€")
                state["reasoning_trace"].append("ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì¤‘ ì‚¬ìš©ì ìš”ì²­ì— ì í•©í•œ ë„êµ¬ê°€ ì—†ì–´ ì§ì ‘ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.")
                state["current_step"] = "no_suitable_tools"
                return state

            # ì²« ë²ˆì§¸ ë°˜ë³µì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ "ì¶”ê°€ ë„êµ¬ ë¶ˆí•„ìš”" ì²´í¬
            if state["iteration_count"] > 0:
                if any(phrase in response_content for phrase in ["ì¶”ê°€ ë„êµ¬ ë¶ˆí•„ìš”", "ì¶”ê°€ì ì¸ ë„êµ¬", "ë” ì´ìƒ", "í•„ìš”í•˜ì§€ ì•Š"]):
                    self.logger.info("ê³„íš ë‹¨ê³„ì—ì„œ ì¶”ê°€ ë„êµ¬ ì‹¤í–‰ì´ ë¶ˆí•„ìš”í•˜ë‹¤ê³  íŒë‹¨ë¨")
                    state["reasoning_trace"].append("ì¶”ê°€ ë„êµ¬ ì‹¤í–‰ì´ ë¶ˆí•„ìš”í•˜ë‹¤ê³  íŒë‹¨ë˜ì–´ ê³„íšì„ ìƒëµí•©ë‹ˆë‹¤.")
                    state["current_step"] = "plan_skipped"
                    return state

            state["reasoning_trace"].append(f"ì‹¤í–‰ ê³„íš: {response.content}")
            state["current_step"] = "plan_ready"

        except Exception as e:
            self.logger.error(f"ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨: {e}")
            state["reasoning_trace"].append(f"ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨: {str(e)}")
            state["current_step"] = "plan_failed"

        return state

    def _find_relevant_tool_by_keywords(self, detected_keywords: List[str]) -> Optional[str]:
        """ê°ì§€ëœ í‚¤ì›Œë“œì— ë§ëŠ” ë„êµ¬ ì°¾ê¸°"""
        if not self.tools:
            return None

        available_tool_names = [getattr(tool, 'name', str(tool)) for tool in self.tools]

        # í‚¤ì›Œë“œë³„ ë„êµ¬ ë§¤ì¹­ ê·œì¹™
        keyword_mappings = {
            'ì‚­ì œ': ['delete', 'remove', 'del'],
            'delete': ['delete', 'remove', 'del'],
            'ì œê±°': ['delete', 'remove', 'del'],
            'remove': ['delete', 'remove', 'del'],
            'ìˆ˜ì •': ['edit', 'modify', 'update'],
            'modify': ['edit', 'modify', 'update'],
            'ë³€ê²½': ['edit', 'modify', 'change'],
            'change': ['edit', 'modify', 'change'],
            'ì‹œê°„': ['time', 'clock', 'current'],
            'time': ['time', 'clock', 'current'],
            'ì‹œìŠ¤í…œ': ['system', 'admin'],
            'system': ['system', 'admin']
        }

        # ê°ì§€ëœ í‚¤ì›Œë“œë¡œ ê´€ë ¨ ë„êµ¬ ì°¾ê¸°
        for keyword in detected_keywords:
            if keyword in keyword_mappings:
                related_terms = keyword_mappings[keyword]

                # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì¤‘ì—ì„œ ê´€ë ¨ ìš©ì–´ê°€ í¬í•¨ëœ ë„êµ¬ ì°¾ê¸°
                for tool_name in available_tool_names:
                    tool_name_lower = tool_name.lower()
                    if any(term in tool_name_lower for term in related_terms):
                        self.logger.info(f"í‚¤ì›Œë“œ '{keyword}'ì— ë§¤ì¹­ë˜ëŠ” ë„êµ¬ ë°œê²¬: {tool_name}")
                        return tool_name

        # ë§¤ì¹­ë˜ëŠ” ë„êµ¬ê°€ ì—†ìŒ
        self.logger.warning(f"í‚¤ì›Œë“œ {detected_keywords}ì— ë§¤ì¹­ë˜ëŠ” ë„êµ¬ë¥¼ ì°¾ì§€ ëª»í•¨")
        return None

    async def _human_approval(self, state: WorkflowState) -> WorkflowState:
        """Human approval ìš”ì²­ ì²˜ë¦¬ - ê°•í™”ëœ ë””ë²„ê¹… ë° ìƒíƒœ ë³´ì¡´"""
        self.logger.info("=== Human approval ìš”ì²­ ì‹œì‘ ===")

        # ìƒíƒœ ì •ë³´ ë” ìì„¸íˆ ë¡œê¹…
        pending_decision = state.get("pending_decision")
        approval_type = state.get("approval_type")
        approval_message = state.get("approval_message")

        self.logger.info(f"ìƒíƒœ í™•ì¸:")
        self.logger.info(f"  - pending_decision ì¡´ì¬: {pending_decision is not None}")
        self.logger.info(f"  - pending_decision íƒ€ì…: {type(pending_decision)}")
        self.logger.info(f"  - approval_type: {approval_type}")
        self.logger.info(f"  - approval_message ì¡´ì¬: {approval_message is not None}")
        self.logger.info(f"  - human_approval_needed: {state.get('human_approval_needed')}")
        self.logger.info(f"  - human_input_callback ì¡´ì¬: {self.human_input_callback is not None}")

        # pending_decisionì´ Noneì¸ ê²½ìš° ìƒíƒœ ì „ì²´ë¥¼ ë¡œê¹…
        if pending_decision is None:
            self.logger.error("âš ï¸ pending_decisionì´ Noneì…ë‹ˆë‹¤!")
            self.logger.error("í˜„ì¬ ìƒíƒœì˜ ëª¨ë“  í‚¤:")
            for key, value in state.items():
                if key in ["pending_decision", "approval_type", "approval_message", "human_approval_needed"]:
                    self.logger.error(f"  {key}: {value} (íƒ€ì…: {type(value)})")

            # ê¸´ê¸‰ ë³µêµ¬ ì‹œë„
            self.logger.info("ê¸´ê¸‰ pending_decision ë³µêµ¬ ì‹œë„...")
            emergency_decision = {
                "type": HumanApprovalType.TOOL_EXECUTION.value,
                "tool_name": "emergency_recovery",
                "tool_args": {"query": state["user_query"]},
                "reason": "ìƒíƒœ ì†ì‹¤ë¡œ ì¸í•œ ê¸´ê¸‰ ë³µêµ¬",
                "keywords": ["ì‚­ì œ"],  # ë¡œê·¸ì—ì„œ ê°ì§€ëœ í‚¤ì›Œë“œ
                "available_tools": [getattr(tool, 'name', str(tool)) for tool in self.tools] if self.tools else [],
                "risk_level": "high"
            }

            state["pending_decision"] = emergency_decision
            pending_decision = emergency_decision
            self.logger.info(f"ê¸´ê¸‰ ë³µêµ¬ ì™„ë£Œ: {emergency_decision}")

        # pending_decision ë‚´ìš© ìƒì„¸ ë¡œê¹…
        if pending_decision:
            self.logger.info(f"pending_decision ìƒì„¸ ë‚´ìš©:")
            for key, value in pending_decision.items():
                self.logger.info(f"  {key}: {value}")

        if not self.hitl_config.get("enabled", False):
            self.logger.info("HITLì´ ë¹„í™œì„±í™”ë¨ - ìë™ ìŠ¹ì¸")
            state["human_response"] = "approved"
            return state

        # ìŠ¹ì¸ ë©”ì‹œì§€ ì¤€ë¹„ - ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ì²˜ë¦¬
        final_approval_message = None

        # 1ìˆœìœ„: ë¯¸ë¦¬ ì„¤ì •ëœ approval_message ì‚¬ìš©
        if approval_message:
            final_approval_message = approval_message
            self.logger.info("ë¯¸ë¦¬ ì„¤ì •ëœ approval_message ì‚¬ìš©")

        # 2ìˆœìœ„: pending_decisionìœ¼ë¡œë¶€í„° ë©”ì‹œì§€ ìƒì„±
        elif pending_decision:
            try:
                final_approval_message = self._create_approval_message(
                    state,
                    pending_decision.get("type", "unknown"),
                    pending_decision
                )
                self.logger.info("pending_decisionìœ¼ë¡œë¶€í„° ìŠ¹ì¸ ë©”ì‹œì§€ ìƒì„±")
            except Exception as e:
                self.logger.error(f"ìŠ¹ì¸ ë©”ì‹œì§€ ìƒì„± ì‹¤íŒ¨: {e}")
                # í´ë°± ë©”ì‹œì§€ ìƒì„±
                final_approval_message = self._create_fallback_approval_message(state, pending_decision)

        # 3ìˆœìœ„: ê¸°ë³¸ í´ë°± ë©”ì‹œì§€
        else:
            self.logger.warning("ìŠ¹ì¸ ì •ë³´ê°€ ì—†ìŒ - ê¸°ë³¸ ë©”ì‹œì§€ ì‚¬ìš©")
            final_approval_message = f"""âš ï¸ ì‘ì—… ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.

ìš”ì²­: {state['user_query']}

ì´ ì‘ì—…ì€ ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (approved/rejected)"""

        # ìŠ¹ì¸ ë©”ì‹œì§€ ë¡œê¹… (ì „ì²´ ë‚´ìš©)
        self.logger.info(f"ìµœì¢… ìŠ¹ì¸ ë©”ì‹œì§€:\n{final_approval_message}")

        try:
            if self.human_input_callback:
                # Callbackì„ í†µí•´ human input ìš”ì²­
                self.logger.info("Human input callback í˜¸ì¶œ ì¤‘...")

                # ë¹„ë™ê¸° í™˜ê²½ ì²´í¬
                try:
                    # ë¹„ë™ê¸° queue ë°©ì‹ ì‹œë„
                    self.waiting_for_human_input = True

                    # Callback í˜¸ì¶œ
                    human_response = self.human_input_callback(final_approval_message, pending_decision or {})

                    # íŠ¹ë³„í•œ í”Œë˜ê·¸ ì²´í¬ - ë¹„ë™ê¸° ì…ë ¥ ëŒ€ê¸°
                    if human_response == "__WAIT_FOR_ASYNC_INPUT__":
                        self.logger.info("ë¹„ë™ê¸° ì…ë ¥ ëŒ€ê¸° ëª¨ë“œ ì§„ì…")
                        self.waiting_for_human_input = True

                        # ë¹„ë™ê¸° ì‘ë‹µ ëŒ€ê¸°
                        try:
                            human_response = await asyncio.wait_for(
                                self.human_input_queue.get(),
                                timeout=300.0  # 5ë¶„ timeout
                            )
                            state["human_response"] = human_response
                            self.logger.info(f"Human ë¹„ë™ê¸° ì‘ë‹µ ìˆ˜ì‹ : {human_response}")
                        except asyncio.TimeoutError:
                            self.logger.error("Human input timeout - ì•ˆì „ì„ ìœ„í•´ ìë™ ê±°ë¶€")
                            state["human_response"] = "rejected"
                            state["reasoning_trace"].append("Human input timeoutìœ¼ë¡œ ì¸í•œ ìë™ ê±°ë¶€")
                    elif isinstance(human_response, str):
                        # ì¼ë°˜ ë¬¸ìì—´ ì‘ë‹µ (ì»¤ìŠ¤í…€ callbackì˜ ê²½ìš°)
                        state["human_response"] = human_response
                        self.logger.info(f"Human callback ë™ê¸° ì‘ë‹µ ìˆ˜ì‹ : {human_response}")
                    else:
                        # ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ íƒ€ì…
                        self.logger.warning(f"ì˜ˆìƒì¹˜ ëª»í•œ callback ì‘ë‹µ íƒ€ì…: {type(human_response)}")
                        state["human_response"] = "rejected"

                except Exception as e:
                    self.logger.error(f"Human input callback ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                    # ì•ˆì „ì„ ìœ„í•´ ê±°ë¶€
                    state["human_response"] = "rejected"
                    state["reasoning_trace"].append(f"Human input callback ì˜¤ë¥˜ë¡œ ì¸í•œ ìë™ ê±°ë¶€: {str(e)}")

                finally:
                    self.waiting_for_human_input = False

                state["reasoning_trace"].append(f"Human approval ì‘ë‹µ: {state.get('human_response', 'none')}")

            else:
                # Human input callbackì´ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°
                self.logger.error("âš ï¸ ì¹˜ëª…ì  ì˜¤ë¥˜: Human input callbackì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ!")
                self.logger.error("ê³ ìœ„í—˜ ì‘ì—…ì´ì§€ë§Œ callbackì´ ì—†ì–´ ìŠ¹ì¸ì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                # ì•ˆì „ì„ ìœ„í•´ ê±°ë¶€ ì²˜ë¦¬
                state["human_response"] = "rejected"
                state["reasoning_trace"].append("Human input callback ë¶€ì¬ë¡œ ì¸í•œ ìë™ ê±°ë¶€")
                self.logger.info("ì•ˆì „ì„ ìœ„í•´ ìë™ ê±°ë¶€ ì²˜ë¦¬ë¨")

        except Exception as e:
            self.logger.error(f"Human approval ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œì—ë„ ìë™ ìŠ¹ì¸ì´ ì•„ë‹Œ ê±°ë¶€ ì²˜ë¦¬
            state["human_response"] = "rejected"
            state["reasoning_trace"].append(f"Human approval ì²˜ë¦¬ ì‹¤íŒ¨ë¡œ ì¸í•œ ìë™ ê±°ë¶€: {str(e)}")

        # ìƒíƒœ ì´ˆê¸°í™”
        state["human_approval_needed"] = False

        self.logger.info(f"=== Human approval ì™„ë£Œ: {state.get('human_response')} ===")
        return state

    async def _human_input(self, state: WorkflowState) -> WorkflowState:
        """Human input ìš”ì²­ ì²˜ë¦¬"""
        self.logger.info("Human input ìš”ì²­ ì¤‘...")

        if not self.hitl_config.get("enabled", False):
            state["human_response"] = "continue"
            return state

        input_message = "ì¶”ê°€ ì •ë³´ë‚˜ ì§€ì‹œì‚¬í•­ì„ ì œê³µí•´ì£¼ì„¸ìš”:"

        try:
            if self.human_input_callback:
                human_input = self.human_input_callback(input_message, {"type": "input_request"})
                state["human_response"] = human_input
                state["reasoning_trace"].append(f"Human input ìˆ˜ì‹ : {human_input}")
                # ë°›ì€ ì…ë ¥ì„ ì‚¬ìš©ì ì¿¼ë¦¬ì— ì¶”ê°€
                state["user_query"] += f"\n[ì¶”ê°€ ì •ë³´: {human_input}]"
            else:
                self.logger.warning("Human input callbackì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                state["human_response"] = "continue"

        except Exception as e:
            self.logger.error(f"Human input ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            state["human_response"] = "continue"

        state["human_input_requested"] = False
        return state

    async def _execute_tools_wrapper(self, state: WorkflowState) -> WorkflowState:
        """ë„êµ¬ ì‹¤í–‰ ë˜í¼ í•¨ìˆ˜"""
        if self.agent_executor:
            return await self.agent_executor.execute_tools(state)
        else:
            self.logger.error("AgentExecutorServiceê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            state["current_step"] = "tools_skipped"
            return state

    async def _evaluate_results_wrapper(self, state: WorkflowState) -> WorkflowState:
        """ê²°ê³¼ í‰ê°€ ë˜í¼ í•¨ìˆ˜"""
        if self.result_aggregator:
            return await self.result_aggregator.evaluate_results(state)
        else:
            self.logger.error("ResultAggregatorServiceê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            state["current_step"] = "evaluation_failed"
            return state

    async def _synthesize_answer_wrapper(self, state: WorkflowState) -> WorkflowState:
        """ë‹µë³€ í•©ì„± ë˜í¼ í•¨ìˆ˜"""
        if self.result_aggregator:
            return await self.result_aggregator.synthesize_answer(state)
        else:
            self.logger.error("ResultAggregatorServiceê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            state["final_answer"] = "ë‹µë³€ í•©ì„± ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            return state

    async def _quality_check(self, state: WorkflowState) -> WorkflowState:
        """í’ˆì§ˆ ê²€ì‚¬"""
        self.logger.info("ë‹µë³€ í’ˆì§ˆ ê²€ì‚¬ ì¤‘...")

        quality_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ë‹µë³€ í’ˆì§ˆì„ ê²€ì‚¬í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€ì„ í‰ê°€í•˜ì„¸ìš”:

1. ì™„ì„±ë„: ì¿¼ë¦¬ì— ì™„ì „íˆ ë‹µí–ˆëŠ”ê°€?
2. ì •í™•ì„±: ì œê³µëœ ì •ë³´ê°€ ì •í™•í•œê°€?
3. ëª…í™•ì„±: ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?
4. ê´€ë ¨ì„±: ì‚¬ìš©ì ìš”ì²­ê³¼ ê´€ë ¨ì´ ìˆëŠ”ê°€?

'approved' ë˜ëŠ” 'retry' ì¤‘ í•˜ë‚˜ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""),
            ("human", """
ì‚¬ìš©ì ì¿¼ë¦¬: {query}
ìƒì„±ëœ ë‹µë³€: {answer}
í’ˆì§ˆì„ í‰ê°€í•´ì£¼ì„¸ìš”.""")
        ])

        try:
            response = await self.evaluator_model.ainvoke(
                quality_prompt.format_messages(
                    query=state["user_query"],
                    answer=state["final_answer"]
                )
            )

            state["next_action"] = "approved" if "approved" in response.content.lower() else "retry"
            state["reasoning_trace"].append(f"í’ˆì§ˆ ê²€ì‚¬: {state['next_action']}")

        except Exception as e:
            self.logger.error(f"í’ˆì§ˆ ê²€ì‚¬ ì‹¤íŒ¨: {e}")
            state["next_action"] = "approved"  # ì‹¤íŒ¨ ì‹œ ìŠ¹ì¸ìœ¼ë¡œ ì²˜ë¦¬

        return state

    async def _simple_answer(self, state: WorkflowState) -> WorkflowState:
        """ë„êµ¬ ì—†ì´ ê°„ë‹¨í•œ ì§ì ‘ ë‹µë³€"""
        self.logger.info("ê°„ë‹¨í•œ ì§ì ‘ ë‹µë³€ ìƒì„± ì¤‘...")

        simple_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ê°„ë‹¨í•œ ì¿¼ë¦¬ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ½ê³  ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

íŠ¹ë³„í•œ ë„êµ¬ë‚˜ ì‹¤ì‹œê°„ ì •ë³´ê°€ í•„ìš”í•˜ì§€ ì•Šì€ ê°„ë‹¨í•œ ì§ˆë¬¸ì´ë¯€ë¡œ, 
ë‹¹ì‹ ì˜ ê¸°ë³¸ ì§€ì‹ê³¼ ëŒ€í™” ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.

ë‹µë³€ì€ ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•˜ì„¸ìš”:
- ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤
- ì ì ˆí•œ ê¸¸ì´ (ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ)
- í•„ìš”ì‹œ ì¶”ê°€ ë„ì›€ ì œì•ˆ"""),
            ("human", "ì‚¬ìš©ì ì¿¼ë¦¬: {query}")
        ])

        try:
            response = await self.model.ainvoke(
                simple_prompt.format_messages(query=state["user_query"])
            )

            state["final_answer"] = response.content
            state["current_step"] = "simple_answer_generated"
            state["reasoning_trace"].append("ê°„ë‹¨í•œ ì§ì ‘ ë‹µë³€ ìƒì„± ì™„ë£Œ")

        except Exception as e:
            self.logger.error(f"ê°„ë‹¨í•œ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°± ë‹µë³€
            if any(greeting in state["user_query"].lower() for greeting in ["ì•ˆë…•", "ë°˜ê°€", "hi", "hello"]):
                state["final_answer"] = "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
            else:
                state["final_answer"] = "ë„¤, ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
            state["current_step"] = "simple_answer_generated"

        return state

    def _create_fallback_approval_message(self, state: WorkflowState, pending_decision: Dict) -> str:
        """í´ë°± ìŠ¹ì¸ ë©”ì‹œì§€ ìƒì„±"""
        keywords = pending_decision.get("keywords", [])
        tool_name = pending_decision.get("tool_name", "ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬")
        risk_level = pending_decision.get("risk_level", "ë³´í†µ")

        risk_emoji = "ğŸ”´" if risk_level == "high" else "ğŸŸ¡"

        return f"""{risk_emoji} ê³ ìœ„í—˜ ì‘ì—… ìŠ¹ì¸ ìš”ì²­

ê°ì§€ëœ í‚¤ì›Œë“œ: {', '.join(keywords) if keywords else 'ì—†ìŒ'}
ì‹¤í–‰ ë„êµ¬: {tool_name}
ìš”ì²­ ë‚´ìš©: {state['user_query']}
ìœ„í—˜ë„: {risk_level}

ì´ ì‘ì—…ì„ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (approved/rejected/modified)"""

    def _create_approval_message(self, state: WorkflowState, approval_type: str, pending_decision: Dict) -> str:
        """ìŠ¹ì¸ ìš”ì²­ ë©”ì‹œì§€ ìƒì„± - ê°œì„ ëœ ë²„ì „"""
        if not pending_decision:
            return "ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. (approved/rejected)"

        if approval_type == HumanApprovalType.TOOL_EXECUTION.value:
            tool_name = pending_decision.get("tool_name", "unknown")
            tool_args = pending_decision.get("tool_args", {})
            reason = pending_decision.get("reason", "ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬")
            keywords = pending_decision.get("keywords", [])
            available_tools = pending_decision.get("available_tools", [])
            risk_level = pending_decision.get("risk_level", "ë³´í†µ")

            # ìœ„í—˜ë„ì— ë”°ë¥¸ ì´ëª¨ì§€ ì„ íƒ
            risk_emoji = "ğŸ”´" if risk_level == "high" else "ğŸŸ¡"

            # ë” ìì„¸í•œ ìŠ¹ì¸ ë©”ì‹œì§€
            message = f"""{risk_emoji} ê³ ìœ„í—˜ ë„êµ¬ ì‹¤í–‰ ìŠ¹ì¸ ìš”ì²­

ê°ì§€ëœ í‚¤ì›Œë“œ: {', '.join(keywords) if keywords else 'ì—†ìŒ'}
ì‹¤í–‰ ì˜ˆì • ë„êµ¬: {tool_name}
ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤: {', '.join(available_tools) if available_tools else 'ì—†ìŒ'}
ì‹¤í–‰ ì¸ìˆ˜: {json.dumps(tool_args, ensure_ascii=False, indent=2)}
ê°ì§€ ì´ìœ : {reason}
ìœ„í—˜ë„: {risk_level}

âš ï¸ ì´ ì‘ì—…ì€ ì‹œìŠ¤í…œì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì •ë§ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (approved/rejected/modified)"""

            return message

        elif approval_type == HumanApprovalType.FINAL_ANSWER.value:
            answer = pending_decision.get("answer", "")
            return f"""âœ… ìµœì¢… ë‹µë³€ ìŠ¹ì¸ ìš”ì²­

ë‹µë³€:
{answer}

ì´ ë‹µë³€ì„ ì‚¬ìš©ìì—ê²Œ ì œê³µí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (approved/rejected/modified)"""

        else:
            content = pending_decision.get("content", "ì•Œ ìˆ˜ ì—†ëŠ” ìš”ì²­")
            return f"""â“ ìŠ¹ì¸ ìš”ì²­

ë‚´ìš©: {content}
ìŠ¹ì¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (approved/rejected)"""

    def _decide_after_analysis(self, state: WorkflowState) -> Literal["simple", "complex"]:
        """ë¶„ì„ ë‹¨ê³„ í›„ ë‹¨ìˆœ/ë³µì¡ ì¿¼ë¦¬ ê²°ì •"""
        current_step = state.get("current_step", "")

        if current_step == "simple_query":
            self.logger.info("ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ íŒë‹¨ - ì§ì ‘ ë‹µë³€ ìƒì„±")
            return "simple"
        else:
            self.logger.info("ë³µì¡í•œ ì¿¼ë¦¬ë¡œ íŒë‹¨ - ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰")
            return "complex"

    def _decide_after_planning(self, state: WorkflowState) -> Literal[
        "execute", "need_approval", "skip_to_synthesize", "end"]:
        """ê³„íš ë‹¨ê³„ í›„ ë‹¤ìŒ ë™ì‘ ê²°ì • (HITL í¬í•¨) - ìˆ˜ì •ëœ ë²„ì „"""
        if state["iteration_count"] >= state["max_iterations"]:
            return "end"

        current_step = state.get("current_step", "")

        if current_step == "plan_skipped":
            return "skip_to_synthesize"
        elif current_step == "no_suitable_tools":
            return "skip_to_synthesize"
        elif current_step == "plan_ready":
            # ë„êµ¬ ì‹¤í–‰ ì „ ìŠ¹ì¸ì´ í•„ìš”í•œì§€ ì²´í¬
            if self._needs_approval_for_tools(state):
                self.logger.info("ë„êµ¬ ìŠ¹ì¸ í•„ìš” - human_approvalë¡œ ë¶„ê¸°")
                # pending_decisionì´ ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
                pending_decision = state.get("pending_decision")
                if pending_decision:
                    self.logger.info(f"pending_decision í™•ì¸ë¨: {pending_decision}")
                    # ìƒíƒœ ì •ë³´ë¥¼ ë” ëª…í™•í•˜ê²Œ ë¡œê¹…
                    self.logger.info(f"approval_type: {state.get('approval_type')}")
                    self.logger.info(f"approval_message ì¡´ì¬: {state.get('approval_message') is not None}")
                else:
                    self.logger.error("pending_decisionì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ!")
                    # ê¸´ê¸‰ ìƒí™© ì²˜ë¦¬ - ê°•ì œë¡œ pending_decision ìƒì„±
                    state["pending_decision"] = {
                        "type": HumanApprovalType.TOOL_EXECUTION.value,
                        "tool_name": "emergency_approval",
                        "tool_args": {"query": state["user_query"]},
                        "reason": "ê¸´ê¸‰ ìŠ¹ì¸ í•„ìš”",
                        "keywords": ["ì‚­ì œ", "ì œê±°"],  # ê¸°ë³¸ ê³ ìœ„í—˜ í‚¤ì›Œë“œ
                        "available_tools": [getattr(tool, 'name', str(tool)) for tool in
                                            self.tools] if self.tools else [],
                        "risk_level": "high"
                    }
                    state["approval_type"] = HumanApprovalType.TOOL_EXECUTION.value
                    self.logger.info("ê¸´ê¸‰ pending_decision ìƒì„±ë¨")
                return "need_approval"
            else:
                return "execute"
        elif current_step == "plan_failed":
            return "end"
        else:
            return "execute"

    def _needs_approval_for_tools(self, state: WorkflowState) -> bool:
        """ë„êµ¬ ì‹¤í–‰ ì „ ìŠ¹ì¸ì´ í•„ìš”í•œì§€ íŒë‹¨ - ê°•í™”ëœ ìƒíƒœ ê´€ë¦¬"""
        if not self.hitl_config.get("enabled", False):
            self.logger.info("HITLì´ ë¹„í™œì„±í™”ë¨")
            return False

        if self.hitl_config.get("require_approval_for_tools", False):
            # ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ê³ ìœ„í—˜ í‚¤ì›Œë“œ ì²´í¬ (ë” ì •í™•í•œ ë§¤ì¹­)
            query_lower = state["user_query"].lower()
            high_impact_keywords = self.hitl_config.get("high_impact_tools", [])

            # ì¿¼ë¦¬ì—ì„œ ê³ ìœ„í—˜ í‚¤ì›Œë“œê°€ ì§ì ‘ ì–¸ê¸‰ëœ ê²½ìš°ë§Œ ì²´í¬
            detected_keywords = []
            for keyword in high_impact_keywords:
                if keyword.lower() in query_lower:
                    detected_keywords.append(keyword)

            if detected_keywords:
                self.logger.info(f"ì¿¼ë¦¬ì—ì„œ ê³ ìœ„í—˜ í‚¤ì›Œë“œ ê°ì§€: {detected_keywords}")

                # ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ í™•ì¸
                available_tools = []
                if self.tools:
                    for tool in self.tools:
                        tool_name = getattr(tool, 'name', str(tool))
                        available_tools.append(tool_name)

                # ê°€ì¥ ì í•©í•œ ë„êµ¬ ì„ íƒ ë˜ëŠ” ì¼ë°˜ì ì¸ ê³ ìœ„í—˜ ì‘ì—…ìœ¼ë¡œ ë¶„ë¥˜
                if available_tools:
                    # ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ ëŒ€í‘œ ë„êµ¬ë¡œ ì‚¬ìš©
                    representative_tool = available_tools[0]
                    tool_description = f"'{representative_tool}' ë„êµ¬ë¥¼ í†µí•œ ê³ ìœ„í—˜ ì‘ì—…"
                else:
                    representative_tool = "system_operation"
                    tool_description = "ì‹œìŠ¤í…œ ì‘ì—…"

                # ìŠ¹ì¸ ë©”ì‹œì§€ ìƒì„±
                approval_message = f"""ğŸ”´ ê³ ìœ„í—˜ ì‘ì—… ìŠ¹ì¸ ìš”ì²­

ê°ì§€ëœ í‚¤ì›Œë“œ: {', '.join(detected_keywords)}
ì‹¤í–‰ ì˜ˆì • ë„êµ¬: {representative_tool}
ì‘ì—… ë‚´ìš©: {tool_description}
ìš”ì²­ ë‚´ìš©: {state['user_query']}
ìœ„í—˜ë„: ë†’ìŒ

âš ï¸ ì´ ì‘ì—…ì€ ì‹œìŠ¤í…œì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì •ë§ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (approved/rejected/modified)"""

                # pending_decision ìƒì„± - ì‹¤ì œ ë„êµ¬ ì •ë³´ ì‚¬ìš©
                pending_decision = {
                    "type": HumanApprovalType.TOOL_EXECUTION.value,
                    "tool_name": representative_tool if available_tools else "ê³ ìœ„í—˜_ì‹œìŠ¤í…œ_ì‘ì—…",
                    "tool_args": {"query": state["user_query"]},
                    "reason": f"ê³ ìœ„í—˜ í‚¤ì›Œë“œ ê°ì§€: {', '.join(detected_keywords)}",
                    "keywords": detected_keywords,
                    "available_tools": available_tools,
                    "risk_level": "high"
                }

                # ìƒíƒœì— ì—¬ëŸ¬ ë°©ì‹ìœ¼ë¡œ ì €ì¥ (ì•ˆì „ì„± í™•ë³´) - ëª…ì‹œì ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸
                state["pending_decision"] = pending_decision
                state["approval_type"] = HumanApprovalType.TOOL_EXECUTION.value
                state["approval_message"] = approval_message
                state["human_approval_needed"] = True

                # ìƒíƒœ ì„¤ì • í™•ì¸ ë¡œê¹…
                self.logger.info(f"HITL ìƒíƒœ ì„¤ì • ì™„ë£Œ:")
                self.logger.info(f"  - ë„êµ¬: {representative_tool}")
                self.logger.info(f"  - í‚¤ì›Œë“œ: {detected_keywords}")
                self.logger.info(f"  - pending_decision íƒ€ì…: {type(state.get('pending_decision'))}")
                self.logger.info(f"  - pending_decision ë‚´ìš©: {state.get('pending_decision')}")

                # ì¦‰ì‹œ ìƒíƒœ ê²€ì¦
                if state.get("pending_decision") is None:
                    self.logger.error("âš ï¸ ì¹˜ëª…ì  ì˜¤ë¥˜: pending_decision ì„¤ì • ì‹¤íŒ¨!")
                    # ê°•ì œë¡œ ë‹¤ì‹œ ì„¤ì •
                    state["pending_decision"] = pending_decision
                    self.logger.info("pending_decision ê°•ì œ ì¬ì„¤ì • ì™„ë£Œ")

                return True

        self.logger.info("ê³ ìœ„í—˜ í‚¤ì›Œë“œê°€ ê°ì§€ë˜ì§€ ì•ŠìŒ - ìŠ¹ì¸ ë¶ˆí•„ìš”")
        return False

    def _decide_after_approval(self, state: WorkflowState) -> Literal["approved", "rejected", "modified", "need_input"]:
        """Human approval í›„ ê²°ì •"""
        human_response = state.get("human_response", "approved").lower()

        if "approved" in human_response or "ìŠ¹ì¸" in human_response:
            return "approved"
        elif "rejected" in human_response or "ê±°ë¶€" in human_response:
            return "rejected"
        elif "modified" in human_response or "ìˆ˜ì •" in human_response:
            return "modified"
        elif "input" in human_response or "ì…ë ¥" in human_response:
            return "need_input"
        else:
            return "approved"  # ê¸°ë³¸ê°’

    def _decide_next_step(self, state: WorkflowState) -> Literal["continue", "synthesize", "need_approval", "end"]:
        """ë‹¤ìŒ ë‹¨ê³„ ê²°ì • (HITL í¬í•¨)"""
        # ë¨¼ì € ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ì²´í¬
        if state["iteration_count"] >= state["max_iterations"]:
            self.logger.info(f"ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜({state['max_iterations']}) ë„ë‹¬ - ì¢…ë£Œ")
            return "end"

        if not state["evaluation_results"]:
            self.logger.info("í‰ê°€ ê²°ê³¼ê°€ ì—†ìŒ - ê³„ì† ì§„í–‰")
            return "continue"

        latest_evaluation = state["evaluation_results"][-1]
        evaluation_type = latest_evaluation.get("evaluation", "")
        confidence = latest_evaluation.get("confidence", 0.0)

        self.logger.info(
            f"í‰ê°€ ê²°ê³¼ í™•ì¸: type={evaluation_type}, confidence={confidence:.2f}, iteration={state['iteration_count']}")

        # ê¸°ì¡´ ë¡œì§
        if confidence >= 1.0:
            self.logger.info(f"ì™„ë²½í•œ ì‹ ë¢°ë„({confidence:.2f}) ë‹¬ì„± - ì¦‰ì‹œ ë‹µë³€ í•©ì„±")
            return "synthesize"
        elif confidence >= 0.95 and evaluation_type == ToolEvaluationResult.SUCCESS.value:
            self.logger.info(f"ë§¤ìš° ë†’ì€ ì‹ ë¢°ë„({confidence:.2f})ì™€ ì„±ê³µ ê²°ê³¼ - ë‹µë³€ í•©ì„±")
            return "synthesize"
        elif evaluation_type == ToolEvaluationResult.SUCCESS.value and confidence >= 0.8:
            self.logger.info(f"ë†’ì€ ì‹ ë¢°ë„({confidence:.2f})ì™€ ì„±ê³µ ê²°ê³¼ - ë‹µë³€ í•©ì„±")
            return "synthesize"
        elif evaluation_type == ToolEvaluationResult.NEEDS_MORE_INFO.value and confidence < 0.9:
            self.logger.info(f"ì¶”ê°€ ì •ë³´ í•„ìš”({confidence:.2f}) - ê³„ì† ì§„í–‰")
            return "continue"
        elif confidence >= 0.7:
            self.logger.info(f"ì ì ˆí•œ ì‹ ë¢°ë„({confidence:.2f}) - ë‹µë³€ í•©ì„±")
            return "synthesize"
        else:
            self.logger.info(f"ë‚®ì€ ì‹ ë¢°ë„({confidence:.2f}) - ê³„ì† ì§„í–‰")
            return "continue"

    def _decide_final_step(self, state: WorkflowState) -> Literal["approved", "retry", "need_approval"]:
        """ìµœì¢… ë‹¨ê³„ ê²°ì • (HITL í¬í•¨)"""
        if state["iteration_count"] >= state["max_iterations"]:
            return "approved"

        # ìµœì¢… ë‹µë³€ ìŠ¹ì¸ì´ í•„ìš”í•œì§€ ì²´í¬
        if (self.hitl_config.get("enabled", False) and
                self.hitl_config.get("require_approval_for_final_answer", False)):
            state["pending_decision"] = {
                "type": HumanApprovalType.FINAL_ANSWER.value,
                "answer": state.get("final_answer", "")
            }
            return "need_approval"

        return state.get("next_action", "approved")

    async def chat_stream(self, message: str, thread_id: str = "default", hitl_enabled: bool = None) -> AsyncGenerator[
        str, None]:
        """Human-in-the-loop ì§€ì› ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ…"""
        if not self.workflow:
            yield "ì›Œí¬í”Œë¡œìš°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            return

        # HITL ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
        if hitl_enabled is not None:
            original_hitl = self.hitl_config["enabled"]
            self.hitl_config["enabled"] = hitl_enabled

        # ì´ˆê¸° ìƒíƒœ ì„¤ì • - ëª¨ë“  í•„ë“œ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
        initial_state = WorkflowState(
            messages=[HumanMessage(content=message)],
            user_query=message,
            current_step="start",
            tool_results=[],
            evaluation_results=[],
            confidence_score=0.0,
            next_action="",
            iteration_count=0,
            max_iterations=3,
            final_answer="",
            reasoning_trace=[],
            # HITL í•„ë“œ ì´ˆê¸°í™”
            human_approval_needed=False,
            human_input_requested=False,
            human_response=None,
            pending_decision=None,
            hitl_enabled=self.hitl_config.get("enabled", False),
            # ì¶”ê°€ HITL ìƒíƒœ
            approval_type=None,
            approval_message=None
        )

        config = {
            "configurable": {"thread_id": thread_id},
            "recursion_limit": 50
        }

        try:
            final_state = None
            step_count = 0
            max_steps = 15
            workflow_completed = False
            answer_provided = False

            async for event in self.workflow.astream(initial_state, config=config):
                step_count += 1
                if step_count > max_steps:
                    self.logger.error(f"ìµœëŒ€ ìŠ¤í… ìˆ˜({max_steps}) ì´ˆê³¼ - ê°•ì œ ì¢…ë£Œ")
                    break

                for node_name, node_state in event.items():
                    # Human approvalì´ë‚˜ inputì´ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
                    if node_name == "human_approval":
                        try:
                            # ì•ˆì „í•œ ìŠ¹ì¸ ë©”ì‹œì§€ ì¶”ì¶œ
                            approval_message = None

                            if node_state.get("approval_message"):
                                approval_message = str(node_state["approval_message"])
                            elif node_state.get("pending_decision"):
                                pending_decision = node_state["pending_decision"]
                                if isinstance(pending_decision, dict):
                                    approval_message = f"""ğŸ¤– ê³ ìœ„í—˜ ì‘ì—… ìŠ¹ì¸ ìš”ì²­

ì‘ì—…: {pending_decision.get('tool_name', 'unknown')}
ìš”ì²­: {node_state.get('user_query', 'unknown')}
ì´ìœ : {pending_decision.get('reason', 'unknown')}

ìŠ¹ì¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (approved/rejected)"""
                            else:
                                approval_message = f"""ğŸ¤– ì‘ì—… ìŠ¹ì¸ ìš”ì²­

ìš”ì²­: {node_state.get('user_query', 'unknown')}
ìŠ¹ì¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (approved/rejected)"""

                            if approval_message:
                                yield f"\nğŸ¤š **Human Approval í•„ìš”**\n{approval_message}\n"
                                self.logger.info("Human Approval ë©”ì‹œì§€ ì „ì†¡ë¨")
                            else:
                                self.logger.warning("Human Approval ë©”ì‹œì§€ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŒ")

                        except Exception as e:
                            self.logger.error(f"Human Approval ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                            # ì•ˆì „í•œ í´ë°± ë©”ì‹œì§€
                            fallback_message = f"ğŸ¤– ì‘ì—… ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.\nìš”ì²­: {message}\nìŠ¹ì¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (approved/rejected)"
                            yield f"\nğŸ¤š **Human Approval í•„ìš”**\n{fallback_message}\n"

                    elif node_name == "human_input":
                        yield f"\nğŸ’­ **Human Input í•„ìš”**\nì¶”ê°€ ì •ë³´ë‚˜ ì§€ì‹œì‚¬í•­ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n"
                        self.logger.info("Human Input ë©”ì‹œì§€ ì „ì†¡ë¨")

                    # ì‹œìŠ¤í…œ ë¡œê·¸
                    if node_state.get("current_step"):
                        self.logger.info(f"ì›Œí¬í”Œë¡œìš° ë‹¨ê³„: {node_state['current_step']} (ë…¸ë“œ: {node_name}) - ìŠ¤í…: {step_count}")

                    final_state = node_state

                    # ë‹µë³€ì´ ì´ë¯¸ ì œê³µë˜ì—ˆëŠ”ì§€ ì²´í¬
                    if node_state.get("final_answer") and not answer_provided:
                        # ì²« ë²ˆì§¸ final_answerê°€ ìƒì„±ë˜ë©´ ì‚¬ìš©ìì—ê²Œ ì œê³µ
                        if node_name in ["synthesize_answer", "simple_answer"]:
                            confidence = node_state.get("confidence_score", 0.0)
                            iterations = node_state.get("iteration_count", 0)
                            self.logger.info(f"ìµœì¢… ë‹µë³€ ìƒì„± - ì‹ ë¢°ë„: {confidence:.2f}, ë°˜ë³µ: {iterations}, ìŠ¤í…: {step_count}")

                            yield node_state["final_answer"]
                            answer_provided = True

                            # quality_checkê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆê±°ë‚˜ ê°„ë‹¨í•œ ë‹µë³€ì´ë©´ ì¦‰ì‹œ ì¢…ë£Œ
                            if (node_name == "simple_answer" or
                                    not self.hitl_config.get("require_approval_for_final_answer", False)):
                                self.logger.info("ë‹µë³€ ì œê³µ ì™„ë£Œ - ì›Œí¬í”Œë¡œìš° ì¡°ê¸° ì¢…ë£Œ")
                                workflow_completed = True
                                break

                    # quality_checkì—ì„œ approvedê°€ ë‚˜ì˜¤ë©´ ì¢…ë£Œ
                    elif (node_name == "quality_check" and
                          node_state.get("next_action") == "approved" and
                          answer_provided):
                        self.logger.info("í’ˆì§ˆ ê²€ì‚¬ í†µê³¼ - ì›Œí¬í”Œë¡œìš° ì¢…ë£Œ")
                        workflow_completed = True
                        break

                # ì›Œí¬í”Œë¡œìš°ê°€ ì™„ë£Œë˜ë©´ ì™¸ë¶€ ë£¨í”„ë„ ì¢…ë£Œ
                if workflow_completed:
                    break

            # ë‹µë³€ì´ ì œê³µë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë§ˆì§€ë§‰ìœ¼ë¡œ ì‹œë„
            if not answer_provided and final_state and final_state.get("final_answer"):
                self.logger.info("ë§ˆì§€ë§‰ ì‹œë„ë¡œ ë‹µë³€ ì œê³µ")
                yield final_state["final_answer"]
            elif not answer_provided:
                yield "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        except Exception as e:
            self.logger.error(f"HITL ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            import traceback
            self.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            yield f"ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

        finally:
            # HITL ì„¤ì • ë³µì›
            if hitl_enabled is not None:
                self.hitl_config["enabled"] = original_hitl

    def create_model(self, model_name: str):
        """ëª¨ë¸ ìƒì„±"""
        output_tokens = {
            "claude-3-5-sonnet-latest": 8192,
            "claude-3-5-haiku-latest": 8192,
            "claude-3-7-sonnet-latest": 64000,
            "gpt-4o": 16000,
            "gpt-4o-mini": 16000,
        }

        if model_name.startswith("claude"):
            return ChatAnthropic(
                model_name=model_name,
                temperature=0.1
            )
        elif model_name.startswith("gpt"):
            return ChatOpenAI(
                model=model_name,
                temperature=0.1,
                max_tokens=output_tokens.get(model_name, 16000)
            )
        elif model_name.startswith("qwen2.5:32b"):
            return ChatOllama(
                model="qwen2.5:32b",
                temperature=0.1
            )
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {model_name}")

    def load_mcp_config(self) -> Dict:
        """MCP ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        config_path = "mcp-config/mcp_config.json"
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            self.logger.warning(f"MCP ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            return {"mcpServers": {}}
        except Exception as e:
            self.logger.error(f"MCP ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {"mcpServers": {}}

    async def get_agent_status(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ìƒíƒœ ì •ë³´ (HITL ì •ë³´ í¬í•¨)"""
        tools_count = len(self.tools) if self.tools else 0

        return {
            "is_initialized": self.workflow is not None,
            "model_name": getattr(self.model, 'model_name', 'Unknown') if self.model else None,
            "evaluator_model": getattr(self.evaluator_model, 'model_name', 'Unknown') if self.evaluator_model else None,
            "tools_count": tools_count,
            "mcp_client_active": self.mcp_client is not None,
            "workflow_active": self.workflow is not None,
            # HITL ìƒíƒœ ì •ë³´
            "hitl_config": self.hitl_config,
            "human_input_callback_set": self.human_input_callback is not None,
            # ë¶„ë¦¬ëœ ì„œë¹„ìŠ¤ ìƒíƒœ ì¶”ê°€
            "agent_executor_initialized": self.agent_executor is not None,
            "result_aggregator_initialized": self.result_aggregator is not None
        }

    async def cleanup_mcp_client(self):
        """MCP í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬"""
        if self.mcp_client:
            try:
                await self.mcp_client.__aexit__(None, None, None)
            except Exception as e:
                self.logger.warning(f"MCP í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            finally:
                self.mcp_client = None
